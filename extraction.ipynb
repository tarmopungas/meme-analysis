{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remove warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# To show all data in dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "raw = pd.read_json(\"data/kym.json\")        # meme templates from Know Your Meme, 16 features\n",
    "events = pd.read_json(\"data/events.json\")  # memes with timestamps from origin and spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Finds SPREAD keywords in memes' spread data\n",
    "# Input: kym dataframe. Output: tuple (list of True/False, list of frequency dictionaries of SPREAD keywords).\n",
    "def matchSpread(memes):\n",
    "    match = []\n",
    "    freq_dics = []\n",
    "    for d in memes['content']:\n",
    "        if 'spread' in d.keys() and 'text' in d['spread'].keys():\n",
    "            dic = {keyword: 0 for keyword in SPREAD}\n",
    "            for text in d['spread']['text']:\n",
    "                words = text.split(\" \")\n",
    "                for word in words:\n",
    "                    if word.lower() in SPREAD:\n",
    "                        dic[word.lower()] += 1\n",
    "            if sum (dic.values()) == 0:\n",
    "                match.append(False)\n",
    "            else:\n",
    "                match.append(True)\n",
    "            freq_dics.append(dic)\n",
    "        else:\n",
    "            match.append(False)\n",
    "    return (match, freq_dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types available: {'song', 'writer', 'technology', 'fauna', 'filmmaker', 'cartoon', 'auction', 'election', 'comedian', 'participatory-media', 'convention', 'shock-media', 'tabletop-games', 'lip-dub', 'character', 'flash-mob', 'athlete', 'country', 'campaign', 'theater', 'artist', 'sound-effect', 'controversy', 'media-host', 'leak', 'viral-debate', 'actor', 'tv-show', 'law', 'prank', 'raid', 'exploitable', 'forum', 'company', 'activist', 'optical-illusion', 'video-game', 'reference', 'news-publication', 'performance', 'webcomic', 'advertisement', 'hashtag', 'conspiracy-theory', 'slang', 'emoticon', 'competition', 'protest', 'visual-effect', 'creepypasta', 'blog', 'axiom', 'comic-book', 'book', 'creator', 'product', 'programmer', 'religion', 'businessperson', 'movement', 'historical-figure', 'vlogger', 'hack', 'fetish', 'disaster', 'trial', 'parody', 'pop-culture-reference', 'food', 'award-ceremony', 'catchphrase', 'manga', 'album', 'organization', 'social-media-page', 'viral-video', 'musician', 'holiday', 'cliche', 'gamer', 'art', 'promotion', 'web-series', 'marketplace', 'application', 'hacker', 'model', 'tv-personality', 'photoshop', 'fan-art', 'reaction', 'music', 'influencer', 'anime', 'hoax', 'snowclone', 'image-macro', 'dance', 'podcast', 'fan-labor', 'generator', 'social-network', 'scientist', 'film', 'social-game', 'sport', 'politician', 'crime', 'remix', 'copypasta', 'animal'}\n",
      "\n",
      "Platforms available (not conclusive): ['Facebook', 'Twitter', 'Instagram', 'Snapchat', 'YouTube', 'WhatsApp', 'TikTok', 'Reddit', 'Pinterest', 'Tumblr', 'LinkedIn', '9GAG', '4chan']\n"
     ]
    }
   ],
   "source": [
    "# See available options for parameters\n",
    "\n",
    "# Types\n",
    "types = set()\n",
    "typedata = raw[raw['details'].map(lambda x: 'type' in x.keys())]['details']\n",
    "for d in typedata:\n",
    "    for t in d['type']:\n",
    "        types.add(t.split(\"https://knowyourmeme.com/types/\")[1])\n",
    "print(\"Types available:\", types)\n",
    "\n",
    "# Spread (keyword search)\n",
    "example_platforms = [\"Facebook\", \"Twitter\", \"Instagram\", \"Snapchat\", \"YouTube\", \"WhatsApp\", \"TikTok\", \"Reddit\", \"Pinterest\", \"Tumblr\", \"LinkedIn\", \"9GAG\", \"4chan\"]\n",
    "print(\"\\nPlatforms available (not conclusive):\", example_platforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select from date (e.g. 2019-05-30). You can leave this empty.  \n",
      "Select to date (e.g. 2021-12-25). You can leave this empty.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When choosing types, use \".\" for OR. Use \";\" for AND. For example: \"snowclone;image-macro.cliche\". Leave empty to include all types.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select types:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When choosing tags, use same system as with type. Leave empty to include all tags.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select tags:  \n"
     ]
    }
   ],
   "source": [
    "# Select parameters for extraction\n",
    "\n",
    "DATE_FROM = input(\"Select from date (e.g. 2019-05-30). You can leave this empty. \")\n",
    "DATE_TO = input(\"Select to date (e.g. 2021-12-25). You can leave this empty. \")\n",
    "\n",
    "# Select if you want to show results with empty about section\n",
    "keepEmptyAbout = False\n",
    "\n",
    "# Meme has at least 1 of the selected types. Keep in mind that roughly half of the memes don't have a type specified.\n",
    "print('\\nWhen choosing types, use \".\" for OR. Use \";\" for AND. For example: \"snowclone;image-macro.cliche\". Leave empty to include all types.')\n",
    "TYPE = input(\"Select types: \")\n",
    "\n",
    "SPREAD = []  # \"Spread\" section of meme contains at least 1 instance of at least 1 of selected keywords. Leave empty to not filter by spread.\n",
    "\n",
    "print('\\nWhen choosing tags, use same system as with type. Leave empty to include all tags.')\n",
    "TAGS = input(\"Select tags: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data based on parameters\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "def extract_data(raw, events, DATE_FROM=\"\", DATE_TO=\"\", TYPE=\"\", SPREAD=[], TAGS=\"\", keepEmptyAbout=True):\n",
    "    # Select only memes\n",
    "    memes = raw[raw['category'] == \"Meme\"] \n",
    "\n",
    "    # Drop duplicates (same title)\n",
    "    memes = memes.loc[memes.astype(str).drop_duplicates(subset=['title']).index]\n",
    "    events = events.loc[events.astype(str).drop_duplicates(subset=['title']).index]\n",
    "\n",
    "    # Merge memes and events (timestamps)\n",
    "    memes = pd.merge(memes, events, on=\"title\")\n",
    "\n",
    "    # Lower-case all parameters just in case\n",
    "    TYPE = TYPE.lower()\n",
    "    SPREAD = [word.lower() for word in SPREAD]\n",
    "    TAGS = TAGS.lower()\n",
    "\n",
    "    # Add \"type\" as separate column of strings\n",
    "    type_col = []\n",
    "    for d in memes['details']:\n",
    "        if 'type' in d.keys():\n",
    "            t_string = \"\"\n",
    "            for t in d['type']:\n",
    "                t_string += t.split(\"https://knowyourmeme.com/types/\")[1] + \", \"\n",
    "            type_col.append(t_string.strip(\", \"))\n",
    "        else:\n",
    "            type_col.append(\"\")\n",
    "    memes['type'] = type_col\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    memes = memes.drop(columns=[\"meta\", \"category\", \"ld\", \"additional_references\", \"search_keywords\", \"parent\", \"siblings\", \"children\"])\n",
    "\n",
    "    # Changing large integers to readable dates\n",
    "    memes['added'] = memes['added'].apply(lambda x: datetime.fromtimestamp(x) if not pd.isnull(x) else x)\n",
    "    memes['last_update_source'] = memes['last_update_source'].apply(lambda x: datetime.fromtimestamp(x) if not pd.isnull(x) else x)\n",
    "\n",
    "    dates = []\n",
    "    for date in memes['last_update_source']:\n",
    "        dates.append(datetime.strptime(str(date)[:10], \"%Y-%m-%d\") if not pd.isnull(date) else 0)\n",
    "    memes['last_update_source'] = dates\n",
    "\n",
    "\n",
    "    # Selecting memes that were last updated in DATE_FROM - DATE_TO\n",
    "    if len(DATE_FROM) > 1 and len(DATE_TO) > 1:\n",
    "        memes = memes[(memes['last_update_source'] >= DATE_FROM) & (memes['last_update_source'] <= DATE_TO)]\n",
    "    elif len(DATE_FROM) > 1:\n",
    "        memes = memes[memes['last_update_source'] >= DATE_FROM]\n",
    "    elif len(DATE_TO) > 1:\n",
    "        memes = memes[memes['last_update_source'] <= DATE_TO]\n",
    "\n",
    "    # Removing entries with empty \"About\" section\n",
    "    if not keepEmptyAbout:\n",
    "        descriptions = []\n",
    "        missing_desc = []\n",
    "        for title, d in zip(memes['title'], memes['content']):\n",
    "            if 'about' in d.keys() and 'text' in d['about'].keys():\n",
    "                descriptions.append(d['about']['text'][0])\n",
    "            else:\n",
    "                missing_desc.append(title)\n",
    "        memes = memes[~memes['title'].isin(missing_desc)]\n",
    "        memes['about'] = descriptions  # Add \"About\" section as a separate column\n",
    "        print(\"Removed {} entries with no About section.\".format(len(missing_desc)))\n",
    "\n",
    "    # Select memes by TYPE    \n",
    "    if len(TYPE) > 1:\n",
    "        typestring = TYPE.replace('.', '\") | type.str.contains(\"').replace(';', '\") & type.str.contains(\"')\n",
    "        typequery = 'type.str.contains(\"' + typestring + '\")'\n",
    "        memes = memes.query(typequery, engine='python')\n",
    "\n",
    "    # Select memes by TAGS    \n",
    "    if len(TAGS) > 1:\n",
    "        # Convert tag column to strings\n",
    "        tag_col = []\n",
    "        for taglist in memes['tags']:\n",
    "            tag_col.append(\", \".join(taglist))\n",
    "        memes['tags'] = tag_col  \n",
    "\n",
    "        tagstring = TAGS.replace('.', '\") | tags.str.contains(\"').replace(';', '\") & tags.str.contains(\"')\n",
    "        tagquery = 'tags.str.contains(\"' + tagstring + '\")'\n",
    "        memes = memes.query(tagquery, engine='python')\n",
    "\n",
    "    # Select memes by SPREAD (content:spread contains at least 1 specified keyword)\n",
    "    if len(SPREAD) > 0:\n",
    "        spread_match, freq_dics = matchSpread(memes)\n",
    "        memes = memes[spread_match]\n",
    "\n",
    "    print(\"Found {} memes matching these criteria.\".format(len(memes)))\n",
    "    return memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12654 memes matching these criteria.\n",
      "{'confirmed': 3266, 'deadpool': 4478, 'submission': 4908, 'unlisted': 2}\n"
     ]
    }
   ],
   "source": [
    "memes = extract_data(raw, events, DATE_FROM=\"\", DATE_TO=\"\", TYPE=\"\", SPREAD=[], TAGS=\"\", keepEmptyAbout=True)\n",
    "\n",
    "# Create dictionary of STATUS values\n",
    "# TODO add this as separate column? @Riccardo\n",
    "\n",
    "status_dict = {}\n",
    "c = 0\n",
    "for d in memes['details']:\n",
    "    if 'status' in d.keys():\n",
    "        status = d['status']\n",
    "        if status in status_dict.keys():\n",
    "            status_dict[status] += 1\n",
    "        else:\n",
    "            status_dict[status] = 1\n",
    "            \n",
    "print(status_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data: reaction, snowclone, exploitable\n",
    "# KYM URL, IMAGE URL, ABOUT Text, Origin Text, [Taglist], Year, Last Updates, [Other Types]\n",
    "memes = memes.drop(columns=[\"origin\"])\n",
    "\n",
    "# Add origin as separate column\n",
    "origin_col = []\n",
    "missing_origin = []\n",
    "for title, d in zip(memes['title'], memes['content']):\n",
    "        if 'origin' in d.keys() and 'text' in d['origin'].keys():\n",
    "            origin_col.append(\" \".join(d['origin']['text']))\n",
    "        else:\n",
    "            missing_origin.append(title)\n",
    "memes = memes[~memes['title'].isin(missing_origin)]  # remove memes that have no \"origin\" specified\n",
    "memes['origin'] = origin_col\n",
    "\n",
    "# Add year as separate column\n",
    "year_col = []\n",
    "missing_year = []\n",
    "for title, d in zip(memes['title'], memes['details']):\n",
    "    if 'year' in d.keys() and d['year'] != None:\n",
    "        year_col.append(d['year'])\n",
    "    else:\n",
    "        missing_year.append(title)\n",
    "memes = memes[~memes['title'].isin(missing_year)]  # remove memes that have no \"year\" specified\n",
    "memes['year'] = year_col\n",
    "\n",
    "# Convert \"type\" back to a list\n",
    "type_col = []\n",
    "for typelist in memes['type']:\n",
    "    t = typelist.split(\", \")\n",
    "    if TYPE in t:\n",
    "        t.remove(TYPE)\n",
    "    type_col.append(t)\n",
    "memes['other_types'] = type_col\n",
    "\n",
    "# Remove rows with empty \"tag\" list\n",
    "missing_tags = []\n",
    "for title, taglist in zip(memes['title'], memes['tags']):\n",
    "    if len(taglist) == 0:\n",
    "        missing_tags.append(title)\n",
    "memes = memes[~memes['title'].isin(missing_tags)]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "memes = memes.drop(columns=[\"title\", \"details\", \"spread\", \"content\", \"added\"])\n",
    "\n",
    "# Reorder columns\n",
    "columns = [\"url\", \"template_image_url\", \"about\", \"origin\", \"tags\", \"year\", \"last_update_source\", \"other_types\"]\n",
    "memes = memes[columns]\n",
    "\n",
    "# TODO: export as csv (separately for three types: filter those out in the top)\n",
    "memes.to_csv(\"out/{}.csv\".format(TYPE), header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stamp \u001b[38;5;129;01min\u001b[39;00m stamplist:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m verb \u001b[38;5;129;01min\u001b[39;00m verbs:\n\u001b[0;32m----> 7\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m verb \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstamp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      8\u001b[0m                 count[verb] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVerb frequency:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(count\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m item: item[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# Collecting most important verbs in events (timestamps)\n",
    "verbs = [\"posted\", \"linked\", \"coined\", \"submitted\", \"made\", \"taken\", \"is\", \"was\", \"recorded\", \"uploaded\", \"began\", \"released\", \"created\", \"appeared\", \"used\", \"begun\", \"began\", \"launched\", \"featured\"]\n",
    "count = {key:0 for key in verbs}\n",
    "for stamplist in memes[\"origin\"]:\n",
    "    for stamp in stamplist:\n",
    "        for verb in verbs:\n",
    "            if verb in stamp[2]:\n",
    "                count[verb] += 1\n",
    "                \n",
    "print(\"Verb frequency:\", dict(sorted(count.items(), key=lambda item: item[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for Toloka\n",
    "\n",
    "# toloka = memes[['template_image_url', 'about']]\n",
    "# toloka.head()\n",
    "# toloka.to_csv(\"out/toloka.tsv\", header = False, index = False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
