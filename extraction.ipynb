{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remove warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# To show all data in dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "raw = pd.read_json(\"data/kym.json\")        # meme templates from Know Your Meme, 16 features\n",
    "events = pd.read_json(\"data/events.json\")  # memes with timestamps from origin and spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds SPREAD keywords in memes' spread data\n",
    "# Input: kym dataframe. Output: tuple (list of True/False, list of frequency dictionaries of SPREAD keywords).\n",
    "def matchSpread(memes):\n",
    "    match = []\n",
    "    freq_dics = []\n",
    "    for d in memes['content']:\n",
    "        if 'spread' in d.keys() and 'text' in d['spread'].keys():\n",
    "            dic = {keyword: 0 for keyword in SPREAD}\n",
    "            for text in d['spread']['text']:\n",
    "                words = text.split(\" \")\n",
    "                for word in words:\n",
    "                    if word.lower() in SPREAD:\n",
    "                        dic[word.lower()] += 1\n",
    "            if sum (dic.values()) == 0:\n",
    "                match.append(False)\n",
    "            else:\n",
    "                match.append(True)\n",
    "            freq_dics.append(dic)\n",
    "        else:\n",
    "            match.append(False)\n",
    "    return (match, freq_dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data based on parameters\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "def extract_data(raw, events, DATE_FROM=\"\", DATE_TO=\"\", TYPE=\"\", SPREAD=[], TAGS=\"\", keep_empty_about=True):\n",
    "    \"\"\"\n",
    "    Returns selection of memes from KYM data merged with Events data. Removes duplicates, drops less relevant columns, parses dates.\n",
    "    \n",
    "    :param raw: Know Your Meme dataset\n",
    "    :param events: Events dataset (timestamps)\n",
    "    :param DATE_FROM: starting date (YYYY-MM-DD) (optional)\n",
    "    :param DATE_TO: starting date (YYYY-MM-DD) (optional)\n",
    "    :param TYPE: meme type(s). Use \".\" for OR. Use \";\" for AND. Example: \"snowclone;image-macro.cliche\". (optional)\n",
    "    :param SPREAD: meme spread by keyword search. \"Spread\" section of meme contains at least 1 instance of at least 1 of selected keywords. (optional)\n",
    "    :param TAGS: meme tag(s). Use \".\" for OR. Use \";\" for AND. Example: \"reddit.video\". (optional)\n",
    "    :param keep_empty_about: include/exclude memes with empty About section (optional)\n",
    "    \"\"\"\n",
    "    # Select only memes\n",
    "    memes = raw[raw['category'] == \"Meme\"] \n",
    "\n",
    "    # Drop duplicates (same title)\n",
    "    memes = memes.loc[memes.astype(str).drop_duplicates(subset=['title']).index]\n",
    "    events = events.loc[events.astype(str).drop_duplicates(subset=['title']).index]\n",
    "\n",
    "    # Merge memes and events (timestamps)\n",
    "    memes = pd.merge(memes, events, on=\"title\")\n",
    "\n",
    "    # Lower-case all parameters just in case\n",
    "    TYPE = TYPE.lower()\n",
    "    SPREAD = [word.lower() for word in SPREAD]\n",
    "    TAGS = TAGS.lower()\n",
    "\n",
    "    # Add \"type\" as separate column\n",
    "    type_col = []\n",
    "    for d in memes['details']:\n",
    "        if 'type' in d.keys():\n",
    "            t_list = []\n",
    "            for t in d['type']:\n",
    "                t_list.append(t.split(\"https://knowyourmeme.com/types/\")[1])\n",
    "            type_col.append(t_list)\n",
    "        else:\n",
    "            type_col.append([])\n",
    "    memes['type'] = type_col\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    memes = memes.drop(columns=[\"meta\", \"category\", \"ld\", \"search_keywords\", \"parent\", \"siblings\", \"children\"])\n",
    "\n",
    "    # Changing large integers to readable dates\n",
    "    memes['added'] = memes['added'].apply(lambda x: datetime.fromtimestamp(x) if not pd.isnull(x) else x)\n",
    "    memes['last_update_source'] = memes['last_update_source'].apply(lambda x: datetime.fromtimestamp(x) if not pd.isnull(x) else x)\n",
    "\n",
    "    dates = []\n",
    "    for date in memes['last_update_source']:\n",
    "        dates.append(datetime.strptime(str(date)[:10], \"%Y-%m-%d\") if not pd.isnull(date) else 0)\n",
    "    memes['last_update_source'] = dates\n",
    "\n",
    "\n",
    "    # Selecting memes that were last updated in DATE_FROM - DATE_TO\n",
    "    if len(DATE_FROM) > 1 and len(DATE_TO) > 1:\n",
    "        memes = memes[(memes['last_update_source'] >= DATE_FROM) & (memes['last_update_source'] <= DATE_TO)]\n",
    "    elif len(DATE_FROM) > 1:\n",
    "        memes = memes[memes['last_update_source'] >= DATE_FROM]\n",
    "    elif len(DATE_TO) > 1:\n",
    "        memes = memes[memes['last_update_source'] <= DATE_TO]\n",
    "\n",
    "    # Removing entries with empty \"About\" section\n",
    "    descriptions = []\n",
    "    missing_desc = []\n",
    "    for title, d in zip(memes['title'], memes['content']):\n",
    "        if 'about' in d.keys() and 'text' in d['about'].keys():\n",
    "            descriptions.append(d['about']['text'][0])\n",
    "        else:\n",
    "            missing_desc.append(title)\n",
    "            if keep_empty_about:\n",
    "                descriptions.append(\"\")\n",
    "    if not keep_empty_about:\n",
    "        memes = memes[~memes['title'].isin(missing_desc)]\n",
    "        print(\"Removed {} entries with no About section.\".format(len(missing_desc)))\n",
    "    memes['about'] = descriptions  # Add \"About\" section as a separate column\n",
    "\n",
    "    # Select memes by TYPE    \n",
    "    if len(TYPE) > 0:\n",
    "        original_typelist = memes['type']\n",
    "        type_col = []\n",
    "        for d in memes['details']:\n",
    "            if 'type' in d.keys():\n",
    "                t_string = \"\"\n",
    "                for t in d['type']:\n",
    "                    t_string += t.split(\"https://knowyourmeme.com/types/\")[1] + \", \"\n",
    "                type_col.append(t_string.strip(\", \"))\n",
    "            else:\n",
    "                type_col.append(\"\")\n",
    "        memes['type'] = type_col\n",
    "        \n",
    "        typestring = TYPE.replace('.', '\") | type.str.contains(\"').replace(';', '\") & type.str.contains(\"')\n",
    "        typequery = 'type.str.contains(\"' + typestring + '\")'\n",
    "        memes = memes.query(typequery, engine='python')\n",
    "        memes['type'] = original_typelist\n",
    "\n",
    "    # Select memes by TAGS    \n",
    "    if len(TAGS) > 0:\n",
    "        # Convert tag column to strings\n",
    "        original_taglist = memes['tags']\n",
    "        tag_col = []\n",
    "        for taglist in memes['tags']:\n",
    "            tag_col.append(\", \".join(taglist))\n",
    "        memes['tags'] = tag_col  \n",
    "\n",
    "        tagstring = TAGS.replace('.', '\") | tags.str.contains(\"').replace(';', '\") & tags.str.contains(\"')\n",
    "        tagquery = 'tags.str.contains(\"' + tagstring + '\")'\n",
    "        memes = memes.query(tagquery, engine='python')\n",
    "        \n",
    "        # Convert tag column back to list\n",
    "        memes['tags'] = original_taglist\n",
    "        \n",
    "\n",
    "    # Select memes by SPREAD (content:spread contains at least 1 specified keyword)\n",
    "    if len(SPREAD) > 0:\n",
    "        spread_match, freq_dics = matchSpread(memes)\n",
    "        memes = memes[spread_match]\n",
    "\n",
    "    print(\"Found {} memes matching these criteria.\".format(len(memes)))\n",
    "    return memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See available options for parameters\n",
    "\n",
    "# Types\n",
    "types = set()\n",
    "typedata = raw[raw['details'].map(lambda x: 'type' in x.keys())]['details']\n",
    "for d in typedata:\n",
    "    for t in d['type']:\n",
    "        types.add(t.split(\"https://knowyourmeme.com/types/\")[1])\n",
    "# print(\"Types available:\", types)\n",
    "\n",
    "# Spread (keyword search)\n",
    "example_platforms = [\"Facebook\", \"Twitter\", \"Instagram\", \"Snapchat\", \"YouTube\", \"WhatsApp\", \"TikTok\", \"Reddit\", \"Pinterest\", \"Tumblr\", \"LinkedIn\", \"9GAG\", \"4chan\"]\n",
    "# print(\"\\nPlatforms available (not conclusive):\", example_platforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 memes matching these criteria.\n"
     ]
    }
   ],
   "source": [
    "# Export data by type (reaction, snowclone, exploitable)\n",
    "TYPE = \"snowclone\"\n",
    "memes = extract_data(raw, events, TYPE=TYPE)\n",
    "memes = memes.drop(columns=[\"origin\"])  # this is NOT the meme Origin section, but from Events data\n",
    "\n",
    "# Add origin as separate column\n",
    "origin_col = []\n",
    "missing_origin = []\n",
    "for title, d in zip(memes['title'], memes['content']):\n",
    "        if 'origin' in d.keys() and 'text' in d['origin'].keys():\n",
    "            origin_col.append(\" \".join(d['origin']['text']))\n",
    "        elif 'origin' in d.keys() and 'subsections' in d['origin'].keys() and len(d['origin']['subsections'].keys()) != 0:\n",
    "            orig_text = \"\"\n",
    "            for key in d['origin']['subsections'].keys():\n",
    "                if 'text' in d['origin']['subsections'][key].keys():\n",
    "                    orig_text += \" \".join(d['origin']['subsections'][key]['text']) + \" \"\n",
    "            if len(orig_text) == 0:\n",
    "                missing_origin.append(title)\n",
    "                origin_col.append(\"\")\n",
    "            else:\n",
    "                origin_col.append(orig_text.strip())\n",
    "        else:\n",
    "            missing_origin.append(title)\n",
    "            origin_col.append(\"\")\n",
    "#memes = memes[~memes['title'].isin(missing_origin)]  # remove memes that have no \"origin\" specified\n",
    "memes['origin'] = origin_col\n",
    "\n",
    "# Add year as separate column\n",
    "year_col = []\n",
    "missing_year = []\n",
    "for title, d in zip(memes['title'], memes['details']):\n",
    "    if 'year' in d.keys() and d['year'] != None:\n",
    "        year_col.append(d['year'])\n",
    "    else:\n",
    "        missing_year.append(title)\n",
    "        year_col.append(\"\")\n",
    "#memes = memes[~memes['title'].isin(missing_year)]  # remove memes that have no \"year\" specified\n",
    "memes['year'] = year_col\n",
    "\n",
    "# Add new column other_types without selected TYPE\n",
    "type_col = []\n",
    "for t in memes['type']:\n",
    "    if TYPE in t:\n",
    "        t.remove(TYPE)\n",
    "    type_col.append(t)\n",
    "memes['other_types'] = type_col\n",
    "\n",
    "# Remove rows with empty \"tag\" list\n",
    "# missing_tags = []\n",
    "# for title, taglist in zip(memes['title'], memes['tags']):\n",
    "#     if len(taglist) == 0:\n",
    "#         missing_tags.append(title)\n",
    "# memes = memes[~memes['title'].isin(missing_tags)]\n",
    "\n",
    "# Check if \"about\" is missing\n",
    "missing_about = []\n",
    "for title, d in zip(memes['title'], memes['content']):\n",
    "        if 'about' in d.keys() and 'text' in d['about'].keys():\n",
    "            pass\n",
    "        else:\n",
    "            missing_about.append(title)\n",
    "\n",
    "# Remove memes that have NEITHER \"about\" nor \"origin\"\n",
    "no_about_origin = set(missing_origin).intersection(set(missing_about))\n",
    "memes = memes[~memes['title'].isin(no_about_origin)] \n",
    "\n",
    "# Add Imgflip references as separate column (some have multiple Imgflip references)                 \n",
    "imgflip_col = []\n",
    "for title, d in zip(memes['title'], memes['additional_references']):\n",
    "    imgf = []\n",
    "    for val in d.values():\n",
    "        if \"imgflip\" in val:\n",
    "            imgf.append(val)\n",
    "    imgflip_col.append(imgf)\n",
    "memes['imgflip'] = imgflip_col\n",
    "\n",
    "# Merge \"about\" and \"origin\" into 1 column\n",
    "# Add new column exist_about_origin for About/Origin: whether we have both, only origin, or only about\n",
    "about_origin = []\n",
    "existing_data = []\n",
    "for about, origin in zip(memes['about'], memes['origin']):\n",
    "    if about == \"\":\n",
    "        about_origin.append(origin)\n",
    "        existing_data.append(\"origin\")\n",
    "    elif origin == \"\":\n",
    "        about_origin.append(about)\n",
    "        existing_data.append(\"about\")\n",
    "    else:\n",
    "        about_origin.append(about + \" \" + origin)\n",
    "        existing_data.append(\"both\")\n",
    "memes['about_origin'] = about_origin\n",
    "memes['exist_about_origin'] = existing_data\n",
    "\n",
    "# Reorder and select columns\n",
    "columns = [\"url\", \"template_image_url\", \"about_origin\", \"tags\", \"year\", \"last_update_source\", \"other_types\", \"imgflip\", \"exist_about_origin\"]\n",
    "memes = memes[columns]\n",
    "\n",
    "# Export all three types as csv\n",
    "# memes.to_csv(\"out/{}.csv\".format(TYPE), header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for Toloka\n",
    "#memes = memes[memes['url'].isin(final_urls)]\n",
    "#toloka = memes[['template_image_url', 'about', 'url']]\n",
    "#toloka.head()\n",
    "#toloka.to_csv(\"out/toloka_about.tsv\", header = False, index = False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for interactive datatable\n",
    "# memes = extract_data(raw, events)\n",
    "# memes = memes[['title', 'url', 'about']]\n",
    "# memes.to_csv(\"out/small_noco.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12654 memes matching these criteria.\n"
     ]
    }
   ],
   "source": [
    "# Manually select memes for Toloka\n",
    "selected_urls = []\n",
    "with open(\"memes_toloka.txt\") as f:\n",
    "    for row in f:\n",
    "        selected_urls.append(row.strip())\n",
    "        \n",
    "memes = extract_data(raw, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "selection = memes[memes['url'].isin(selected_urls)]\n",
    "#final_urls = set()\n",
    "c = 0\n",
    "for url, about, ty in zip(selection['url'], selection['about'], selection['type']):\n",
    "    if \"exploitable\" in ty and len(ty) == 1 and \"snowclone\" not in about and \"reaction\" not in about:\n",
    "        if len(final_urls) < 50:\n",
    "            final_urls.add(url)\n",
    "        c += 1\n",
    "    #if \"snowclone\" in about:\n",
    "        #c += 1\n",
    "        #final_urls.add(url)\n",
    "\n",
    "print(c)\n",
    "print(len(final_urls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
